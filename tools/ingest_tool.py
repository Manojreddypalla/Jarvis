# tools/ingest_tool.py

from pathlib import Path

from langchain_community.document_loaders import (
    PyPDFLoader,
    UnstructuredMarkdownLoader,
    UnstructuredWordDocumentLoader
)

from langchain_text_splitters import RecursiveCharacterTextSplitter

from langchain_ollama import OllamaEmbeddings
from langchain_qdrant import QdrantVectorStore


BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / "data"

QDRANT_URL = "http://localhost:6333"
COLLECTION = "learning_rag"

EMBED_MODEL = "mxbai-embed-large"
BASE_URL = "http://localhost:11434"


def ingest_data_folder(_=None):

    logs = []

    logs.append("ğŸ“‚ Scanning data folder...")

    if not DATA_DIR.exists():
        return "âŒ data/ folder not found"


    files = list(DATA_DIR.glob("*"))

    if not files:
        return "â„¹ï¸ No files found in data folder"


    logs.append(f"ğŸ“ Found {len(files)} files")


    all_chunks = []

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1200,
        chunk_overlap=200
    )


    for i, file in enumerate(files, start=1):

        suffix = file.suffix.lower()

        logs.append(f"ğŸ“„ [{i}/{len(files)}] Processing {file.name}")


        try:

            if suffix == ".pdf":
                loader = PyPDFLoader(str(file))

            elif suffix == ".md":
                loader = UnstructuredMarkdownLoader(str(file))

            elif suffix in [".docx", ".doc"]:
                loader = UnstructuredWordDocumentLoader(str(file))

            else:
                logs.append("âš ï¸ Skipped (unsupported format)")
                continue


            docs = loader.load()
            chunks = splitter.split_documents(docs)

            logs.append(f"   ğŸ“¦ {len(chunks)} chunks created")

            all_chunks.extend(chunks)

            file.unlink()

            logs.append("   ğŸ—‘ï¸ File deleted")


        except Exception as e:

            logs.append(f"âŒ Failed: {file.name} â†’ {e}")


    if not all_chunks:
        return "âš ï¸ No valid documents processed"


    logs.append("ğŸ§  Initializing embeddings...")

    embedder = OllamaEmbeddings(
        model=EMBED_MODEL,
        base_url=BASE_URL
    )


    logs.append(f"ğŸš€ Embedding {len(all_chunks)} chunks...")


    QdrantVectorStore.from_documents(
        documents=all_chunks,
        embedding=embedder,
        url=QDRANT_URL,
        collection_name=COLLECTION
    )


    logs.append("âœ… Stored in vector DB")
    logs.append("ğŸ‰ Ingestion complete!")


    return "\n".join(logs)
